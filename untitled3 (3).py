# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ffPXN_V0IpSc07YpKm-6MMBFCEe5PfnH
"""

import nltk
import pandas as pd
# nltk.download()
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re
# nltk.download('punkt')
from nltk.stem.wordnet import WordNetLemmatizer 
nltk.download('wordnet')
# nltk.download('stopwords')

df  = pd.read_csv('nlpfile.csv', dtype=str)

df['Columns name'] = df['Columns name'].str.lower().str.replace(r'[^A-Za-z0-9]+', ' ')
stop =set(stopwords.words('english')) 
df['tokenized_text'] = df['Columns name'].apply(word_tokenize).apply(lambda x: [item for item in x if item not in stop])

# print(column_list)

lmtzr = WordNetLemmatizer()
df['lemmatize'] = df['tokenized_text'].apply(
                    lambda lst:[lmtzr.lemmatize(word) for word in lst])
# print(df['lemmatize'])
column_list =list(df['lemmatize'])

def consolidate(sets):
    setlist = [s for s in sets if s]
    for i, s1 in enumerate(setlist):
        if s1:
            for s2 in setlist[i+1:]:
                intersection = s1.intersection(s2)
                if intersection:
                    s2.update(s1)
                    s1.clear()
                    s1 = s2
    return [s for s in setlist if s]

def wrapper(seqs):
    consolidated = consolidate(map(set, seqs))
    groupmap = {x: i for i,seq in enumerate(consolidated) for x in seq}
    output = {}
    for seq in seqs:
        target = output.setdefault(groupmap[seq[0]], [])
        target.append(seq)
    return list(output.values())
grps=[]
for i, group in enumerate(wrapper(column_list)):
  group
  grps.append(group)
  # print(grps)
l=[]
for i in range(len(grps)):
  res = list(map(" ".join, grps[i]))
  l.append(res)
# print (l)
print(l[0])

df1 = pd.DataFrame({'samples': l})
df2 = df.join(df1 )
df2.to_csv('output1.csv')